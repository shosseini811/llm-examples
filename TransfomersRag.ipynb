{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuT/vBfPMIwP1BCYYfVfRE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shosseini811/llm-examples/blob/main/TransfomersRag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1B-XQyMP9XJF",
        "outputId": "bf40720b-63df-4b95-e81b-e7196c3f7426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "af11e45ac46f4b178f5e93612a4301fe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Query and documents\n",
        "query = \"What is the capital of France?\"\n",
        "documents = [\n",
        "    \"The capital of France is Paris.\",\n",
        "    \"France is a country in Europe.\",\n",
        "    \"Paris is a major city.\"\n",
        "]\n",
        "doc_probs = [0.7, 0.2, 0.1]  # p(z|x) for each document\n",
        "\n",
        "# Function to get token probabilities for a response given a document\n",
        "def get_token_probs(query, document, response):\n",
        "    input_text = f\"{query} {document}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Tokenize the response and get token strings for display\n",
        "    response_ids = tokenizer.encode(response, add_special_tokens=False)\n",
        "    response_tokens = tokenizer.convert_ids_to_tokens(response_ids)\n",
        "\n",
        "    print(f\"\\nTokenized response: {response_tokens}\")\n",
        "\n",
        "    # Calculate probabilities for each token\n",
        "    token_probs = []\n",
        "    for i, token_id in enumerate(response_ids):\n",
        "        token = response_tokens[i]\n",
        "\n",
        "        # Create input with previous response tokens\n",
        "        if i == 0:\n",
        "            curr_input_ids = input_ids\n",
        "            context = tokenizer.decode(input_ids[0])\n",
        "        else:\n",
        "            prev_tokens = response_ids[:i]\n",
        "            curr_input_ids = torch.cat([input_ids, torch.tensor([prev_tokens]).to(input_ids.device)], dim=1)\n",
        "            context = tokenizer.decode(input_ids[0]) + \" \" + tokenizer.decode(prev_tokens)\n",
        "\n",
        "        # Get model output\n",
        "        with torch.no_grad():\n",
        "            outputs = model(curr_input_ids)\n",
        "            logits = outputs.logits[:, -1, :]\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            token_prob = probs[0, token_id].item()\n",
        "            token_probs.append(token_prob)\n",
        "\n",
        "            print(f\"  Token: '{token}' | Probability: {token_prob:.6f} | Given context: '{context}'\")\n",
        "\n",
        "    # Calculate p(y|x,z) as product of token probabilities\n",
        "    sequence_prob = torch.prod(torch.tensor(token_probs)).item()\n",
        "    print(f\"  p(y|x,z) = {' × '.join([f'{p:.6f}' for p in token_probs])} = {sequence_prob:.10f}\")\n",
        "\n",
        "    return sequence_prob, token_probs\n",
        "\n",
        "# Calculate RAG-Sequence probability\n",
        "response = \"The capital is Paris\"\n",
        "rag_sequence_prob = 0\n",
        "all_doc_contributions = []\n",
        "\n",
        "print(f\"Query: '{query}'\")\n",
        "print(f\"Response: '{response}'\")\n",
        "\n",
        "for i, (doc, doc_prob) in enumerate(zip(documents, doc_probs)):\n",
        "    print(f\"\\n--- Document {i+1}: '{doc}' (p(z|x) = {doc_prob}) ---\")\n",
        "\n",
        "    # Calculate p(y|x,z) for this document\n",
        "    response_prob, token_probs = get_token_probs(query, doc, response)\n",
        "\n",
        "    # Calculate contribution to final probability\n",
        "    contribution = doc_prob * response_prob\n",
        "    all_doc_contributions.append(contribution)\n",
        "\n",
        "    print(f\"  Contribution to final probability: {doc_prob} × {response_prob:.10f} = {contribution:.10f}\")\n",
        "\n",
        "    # Add to weighted sum: p(z|x) * p(y|x,z)\n",
        "    rag_sequence_prob += contribution\n",
        "\n",
        "print(\"\\n--- Final RAG-Sequence Probability ---\")\n",
        "print(f\"p_RAG-Sequence(y|x) = {' + '.join([f'{c:.10f}' for c in all_doc_contributions])} = {rag_sequence_prob:.10f}\")\n",
        "\n",
        "# Additional analysis - which document contributed most?\n",
        "max_contribution_idx = all_doc_contributions.index(max(all_doc_contributions))\n",
        "print(f\"\\nDocument with highest contribution: Document {max_contribution_idx+1} ('{documents[max_contribution_idx]}')\")\n",
        "print(f\"Percentage of final probability: {(all_doc_contributions[max_contribution_idx]/rag_sequence_prob)*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixL-4nmp8urk",
        "outputId": "f9757eac-0812-48d9-f499-8dd301d63665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 'What is the capital of France?'\n",
            "Response: 'The capital is Paris'\n",
            "\n",
            "--- Document 1: 'The capital of France is Paris.' (p(z|x) = 0.7) ---\n",
            "\n",
            "Tokenized response: ['The', 'Ġcapital', 'Ġis', 'ĠParis']\n",
            "  Token: 'The' | Probability: 0.000208 | Given context: 'What is the capital of France? The capital of France is Paris.'\n",
            "  Token: 'Ġcapital' | Probability: 0.782313 | Given context: 'What is the capital of France? The capital of France is Paris. The'\n",
            "  Token: 'Ġis' | Probability: 0.018124 | Given context: 'What is the capital of France? The capital of France is Paris. The capital'\n",
            "  Token: 'ĠParis' | Probability: 0.362402 | Given context: 'What is the capital of France? The capital of France is Paris. The capital is'\n",
            "  p(y|x,z) = 0.000208 × 0.782313 × 0.018124 × 0.362402 = 0.0000010703\n",
            "  Contribution to final probability: 0.7 × 0.0000010703 = 0.0000007492\n",
            "\n",
            "--- Document 2: 'France is a country in Europe.' (p(z|x) = 0.2) ---\n",
            "\n",
            "Tokenized response: ['The', 'Ġcapital', 'Ġis', 'ĠParis']\n",
            "  Token: 'The' | Probability: 0.000134 | Given context: 'What is the capital of France? France is a country in Europe.'\n",
            "  Token: 'Ġcapital' | Probability: 0.356573 | Given context: 'What is the capital of France? France is a country in Europe. The'\n",
            "  Token: 'Ġis' | Probability: 0.120579 | Given context: 'What is the capital of France? France is a country in Europe. The capital'\n",
            "  Token: 'ĠParis' | Probability: 0.115051 | Given context: 'What is the capital of France? France is a country in Europe. The capital is'\n",
            "  p(y|x,z) = 0.000134 × 0.356573 × 0.120579 × 0.115051 = 0.0000006619\n",
            "  Contribution to final probability: 0.2 × 0.0000006619 = 0.0000001324\n",
            "\n",
            "--- Document 3: 'Paris is a major city.' (p(z|x) = 0.1) ---\n",
            "\n",
            "Tokenized response: ['The', 'Ġcapital', 'Ġis', 'ĠParis']\n",
            "  Token: 'The' | Probability: 0.000132 | Given context: 'What is the capital of France? Paris is a major city.'\n",
            "  Token: 'Ġcapital' | Probability: 0.372634 | Given context: 'What is the capital of France? Paris is a major city. The'\n",
            "  Token: 'Ġis' | Probability: 0.191379 | Given context: 'What is the capital of France? Paris is a major city. The capital'\n",
            "  Token: 'ĠParis' | Probability: 0.038606 | Given context: 'What is the capital of France? Paris is a major city. The capital is'\n",
            "  p(y|x,z) = 0.000132 × 0.372634 × 0.191379 × 0.038606 = 0.0000003641\n",
            "  Contribution to final probability: 0.1 × 0.0000003641 = 0.0000000364\n",
            "\n",
            "--- Final RAG-Sequence Probability ---\n",
            "p_RAG-Sequence(y|x) = 0.0000007492 + 0.0000001324 + 0.0000000364 = 0.0000009180\n",
            "\n",
            "Document with highest contribution: Document 1 ('The capital of France is Paris.')\n",
            "Percentage of final probability: 81.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Query and expanded set of documents\n",
        "query = \"What are some interesting facts about Paris, France?\"\n",
        "documents = [\n",
        "    \"Paris is the capital of France and is known as the City of Light.\",\n",
        "    \"The Eiffel Tower in Paris was built for the 1889 World's Fair and stands 324 meters tall.\",\n",
        "    \"France is a country in Western Europe with a population of about 67 million people.\",\n",
        "    \"Paris hosts many famous museums including the Louvre, which houses the Mona Lisa.\",\n",
        "    \"The Seine River flows through Paris and has 37 bridges within the city limits.\",\n",
        "    \"French cuisine is famous worldwide, with Paris having over 70 Michelin-starred restaurants.\",\n",
        "    \"The Notre-Dame Cathedral in Paris began construction in 1163 and was damaged by fire in 2019.\"\n",
        "]\n",
        "# Assign probabilities to documents based on relevance to query\n",
        "doc_probs = [0.25, 0.20, 0.05, 0.18, 0.12, 0.08, 0.12]  # p(z|x) for each document\n",
        "\n",
        "# Function to get token probabilities for a response given a document\n",
        "def get_token_probs(query, document, response):\n",
        "    input_text = f\"{query} {document}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Tokenize the response and get token strings for display\n",
        "    response_ids = tokenizer.encode(response, add_special_tokens=False)\n",
        "    response_tokens = tokenizer.convert_ids_to_tokens(response_ids)\n",
        "\n",
        "    print(f\"\\nTokenized response ({len(response_tokens)} tokens): {response_tokens}\")\n",
        "\n",
        "    # Calculate probabilities for each token\n",
        "    token_probs = []\n",
        "    for i, token_id in enumerate(response_ids):\n",
        "        token = response_tokens[i]\n",
        "\n",
        "        # Create input with previous response tokens\n",
        "        if i == 0:\n",
        "            curr_input_ids = input_ids\n",
        "            context = tokenizer.decode(input_ids[0])\n",
        "        else:\n",
        "            prev_tokens = response_ids[:i]\n",
        "            curr_input_ids = torch.cat([input_ids, torch.tensor([prev_tokens]).to(input_ids.device)], dim=1)\n",
        "            context = tokenizer.decode(input_ids[0]) + \" \" + tokenizer.decode(prev_tokens)\n",
        "\n",
        "        # Get model output\n",
        "        with torch.no_grad():\n",
        "            outputs = model(curr_input_ids)\n",
        "            logits = outputs.logits[:, -1, :]\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            token_prob = probs[0, token_id].item()\n",
        "            token_probs.append(token_prob)\n",
        "\n",
        "            # For brevity, only show first 50 chars of context\n",
        "            short_context = context[:50] + \"...\" if len(context) > 50 else context\n",
        "            print(f\"  Token: '{token}' | Probability: {token_prob:.6f} | Given context: '{short_context}...'\")\n",
        "\n",
        "    # Calculate p(y|x,z) as product of token probabilities\n",
        "    sequence_prob = torch.prod(torch.tensor(token_probs)).item()\n",
        "\n",
        "    # For readability, only show first few and last few token probabilities if there are many\n",
        "    if len(token_probs) > 8:\n",
        "        prob_str = f\"{' × '.join([f'{p:.6f}' for p in token_probs[:3]])} × ... × {' × '.join([f'{p:.6f}' for p in token_probs[-3:]])}\"\n",
        "    else:\n",
        "        prob_str = f\"{' × '.join([f'{p:.6f}' for p in token_probs])}\"\n",
        "\n",
        "    print(f\"  p(y|x,z) = {prob_str} = {sequence_prob:.10f}\")\n",
        "\n",
        "    return sequence_prob, token_probs\n",
        "\n",
        "# More complex response\n",
        "response = \"Paris is the capital of France and is famous for the Eiffel Tower, which was built in 1889. The city is known for its art museums like the Louvre and its beautiful architecture.\"\n",
        "\n",
        "rag_sequence_prob = 0\n",
        "all_doc_contributions = []\n",
        "\n",
        "print(f\"Query: '{query}'\")\n",
        "print(f\"Response: '{response}'\")\n",
        "\n",
        "# Calculate document contributions\n",
        "for i, (doc, doc_prob) in enumerate(zip(documents, doc_probs)):\n",
        "    print(f\"\\n--- Document {i+1}: '{doc}' (p(z|x) = {doc_prob}) ---\")\n",
        "\n",
        "    # Calculate p(y|x,z) for this document\n",
        "    response_prob, token_probs = get_token_probs(query, doc, response)\n",
        "\n",
        "    # Calculate contribution to final probability\n",
        "    contribution = doc_prob * response_prob\n",
        "    all_doc_contributions.append(contribution)\n",
        "\n",
        "    print(f\"  Contribution to final probability: {doc_prob} × {response_prob:.10f} = {contribution:.10f}\")\n",
        "\n",
        "    # Add to weighted sum: p(z|x) * p(y|x,z)\n",
        "    rag_sequence_prob += contribution\n",
        "\n",
        "print(\"\\n--- Final RAG-Sequence Probability ---\")\n",
        "print(f\"p_RAG-Sequence(y|x) = {' + '.join([f'{c:.10e}' for c in all_doc_contributions])} = {rag_sequence_prob:.10e}\")\n",
        "\n",
        "# Additional analysis\n",
        "print(\"\\n--- Document Contribution Analysis ---\")\n",
        "# Sort documents by contribution\n",
        "sorted_contributions = sorted([(i, doc, prob, contrib)\n",
        "                              for i, (doc, prob, contrib) in\n",
        "                              enumerate(zip(documents, doc_probs, all_doc_contributions))],\n",
        "                             key=lambda x: x[3], reverse=True)\n",
        "\n",
        "# Show contribution breakdown\n",
        "for i, doc, prob, contrib in sorted_contributions:\n",
        "    percentage = (contrib/rag_sequence_prob)*100\n",
        "    print(f\"Document {i+1}: {percentage:.2f}% of final probability\")\n",
        "    print(f\"  - Content: '{doc}'\")\n",
        "    print(f\"  - p(z|x): {prob}\")\n",
        "    print(f\"  - Contribution: {contrib:.10e}\\n\")\n",
        "\n",
        "# Token analysis - which documents gave highest probabilities for key tokens\n",
        "print(\"--- Token Probability Analysis ---\")\n",
        "# For demonstration, analyze a few key tokens in the response\n",
        "key_tokens = [\"Paris\", \"Eiffel\", \"Tower\", \"Louvre\"]\n",
        "tokenized_response = tokenizer.encode(response, add_special_tokens=False)\n",
        "response_tokens = tokenizer.convert_ids_to_tokens(tokenized_response)\n",
        "\n",
        "for key_token in key_tokens:\n",
        "    print(f\"\\nAnalyzing token: '{key_token}'\")\n",
        "    # Find positions of this token in the response\n",
        "    positions = [i for i, token in enumerate(response_tokens) if key_token.lower() in token.lower()]\n",
        "\n",
        "    if positions:\n",
        "        for pos in positions:\n",
        "            print(f\"  Position {pos} ('{response_tokens[pos]}')\")\n",
        "            # Compare probabilities across documents\n",
        "            token_probs_across_docs = []\n",
        "            for i, doc in enumerate(documents):\n",
        "                input_text = f\"{query} {doc}\"\n",
        "                input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "                # Get previous tokens\n",
        "                prev_tokens = tokenized_response[:pos]\n",
        "                if prev_tokens:\n",
        "                    curr_input_ids = torch.cat([input_ids, torch.tensor([prev_tokens]).to(input_ids.device)], dim=1)\n",
        "                else:\n",
        "                    curr_input_ids = input_ids\n",
        "\n",
        "                # Get probability\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(curr_input_ids)\n",
        "                    logits = outputs.logits[:, -1, :]\n",
        "                    probs = torch.softmax(logits, dim=-1)\n",
        "                    token_prob = probs[0, tokenized_response[pos]].item()\n",
        "                    token_probs_across_docs.append((i, token_prob))\n",
        "\n",
        "            # Sort and display\n",
        "            token_probs_across_docs.sort(key=lambda x: x[1], reverse=True)\n",
        "            for i, prob in token_probs_across_docs[:3]:  # Show top 3\n",
        "                print(f\"    Doc {i+1}: {prob:.6f} - '{documents[i][:50]}...'\")\n",
        "    else:\n",
        "        print(f\"  Token not found directly in response\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrS0ouM29ADq",
        "outputId": "96140e1f-c2dd-440d-9c68-18bc2cac948a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 'What are some interesting facts about Paris, France?'\n",
            "Response: 'Paris is the capital of France and is famous for the Eiffel Tower, which was built in 1889. The city is known for its art museums like the Louvre and its beautiful architecture.'\n",
            "\n",
            "--- Document 1: 'Paris is the capital of France and is known as the City of Light.' (p(z|x) = 0.25) ---\n",
            "\n",
            "Tokenized response (39 tokens): ['Paris', 'Ġis', 'Ġthe', 'Ġcapital', 'Ġof', 'ĠFrance', 'Ġand', 'Ġis', 'Ġfamous', 'Ġfor', 'Ġthe', 'ĠE', 'iff', 'el', 'ĠTower', ',', 'Ġwhich', 'Ġwas', 'Ġbuilt', 'Ġin', 'Ġ1889', '.', 'ĠThe', 'Ġcity', 'Ġis', 'Ġknown', 'Ġfor', 'Ġits', 'Ġart', 'Ġmuseums', 'Ġlike', 'Ġthe', 'ĠLou', 'vre', 'Ġand', 'Ġits', 'Ġbeautiful', 'Ġarchitecture', '.']\n",
            "  Token: 'Paris' | Probability: 0.000183 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.657991 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.160227 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcapital' | Probability: 0.194610 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġof' | Probability: 0.929777 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠFrance' | Probability: 0.326009 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.370183 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.829381 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfamous' | Probability: 0.005664 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.630979 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.086364 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠE' | Probability: 0.000387 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'iff' | Probability: 0.984443 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'el' | Probability: 0.998633 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠTower' | Probability: 0.968607 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: ',' | Probability: 0.286325 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwhich' | Probability: 0.077799 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwas' | Probability: 0.139294 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbuilt' | Probability: 0.447995 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġin' | Probability: 0.401752 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġ1889' | Probability: 0.009120 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.443637 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠThe' | Probability: 0.122265 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcity' | Probability: 0.194780 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.430455 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġknown' | Probability: 0.070845 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.459106 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.486272 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġart' | Probability: 0.005000 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġmuseums' | Probability: 0.054994 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġlike' | Probability: 0.007253 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.307897 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠLou' | Probability: 0.026561 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'vre' | Probability: 0.997939 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.287294 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.012835 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbeautiful' | Probability: 0.004791 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġarchitecture' | Probability: 0.022355 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.636876 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  p(y|x,z) = 0.000183 × 0.657991 × 0.160227 × ... × 0.004791 × 0.022355 × 0.636876 = 0.0000000000\n",
            "  Contribution to final probability: 0.25 × 0.0000000000 = 0.0000000000\n",
            "\n",
            "--- Document 2: 'The Eiffel Tower in Paris was built for the 1889 World's Fair and stands 324 meters tall.' (p(z|x) = 0.2) ---\n",
            "\n",
            "Tokenized response (39 tokens): ['Paris', 'Ġis', 'Ġthe', 'Ġcapital', 'Ġof', 'ĠFrance', 'Ġand', 'Ġis', 'Ġfamous', 'Ġfor', 'Ġthe', 'ĠE', 'iff', 'el', 'ĠTower', ',', 'Ġwhich', 'Ġwas', 'Ġbuilt', 'Ġin', 'Ġ1889', '.', 'ĠThe', 'Ġcity', 'Ġis', 'Ġknown', 'Ġfor', 'Ġits', 'Ġart', 'Ġmuseums', 'Ġlike', 'Ġthe', 'ĠLou', 'vre', 'Ġand', 'Ġits', 'Ġbeautiful', 'Ġarchitecture', '.']\n",
            "  Token: 'Paris' | Probability: 0.000026 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.342221 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.148437 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcapital' | Probability: 0.038970 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġof' | Probability: 0.788935 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠFrance' | Probability: 0.527694 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.289432 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.197339 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfamous' | Probability: 0.017578 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.821063 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.074928 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠE' | Probability: 0.002845 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'iff' | Probability: 0.999975 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'el' | Probability: 0.998692 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠTower' | Probability: 0.952785 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: ',' | Probability: 0.292584 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwhich' | Probability: 0.189908 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwas' | Probability: 0.161019 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbuilt' | Probability: 0.327711 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġin' | Probability: 0.284278 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġ1889' | Probability: 0.127820 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.236616 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠThe' | Probability: 0.223626 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcity' | Probability: 0.013703 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.296886 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġknown' | Probability: 0.064829 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.696507 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.587750 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġart' | Probability: 0.005497 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġmuseums' | Probability: 0.040958 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġlike' | Probability: 0.006903 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.303401 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠLou' | Probability: 0.028879 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'vre' | Probability: 0.998059 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.296407 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.011896 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbeautiful' | Probability: 0.004764 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġarchitecture' | Probability: 0.022067 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.642181 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  p(y|x,z) = 0.000026 × 0.342221 × 0.148437 × ... × 0.004764 × 0.022067 × 0.642181 = 0.0000000000\n",
            "  Contribution to final probability: 0.2 × 0.0000000000 = 0.0000000000\n",
            "\n",
            "--- Document 3: 'France is a country in Western Europe with a population of about 67 million people.' (p(z|x) = 0.05) ---\n",
            "\n",
            "Tokenized response (39 tokens): ['Paris', 'Ġis', 'Ġthe', 'Ġcapital', 'Ġof', 'ĠFrance', 'Ġand', 'Ġis', 'Ġfamous', 'Ġfor', 'Ġthe', 'ĠE', 'iff', 'el', 'ĠTower', ',', 'Ġwhich', 'Ġwas', 'Ġbuilt', 'Ġin', 'Ġ1889', '.', 'ĠThe', 'Ġcity', 'Ġis', 'Ġknown', 'Ġfor', 'Ġits', 'Ġart', 'Ġmuseums', 'Ġlike', 'Ġthe', 'ĠLou', 'vre', 'Ġand', 'Ġits', 'Ġbeautiful', 'Ġarchitecture', '.']\n",
            "  Token: 'Paris' | Probability: 0.000019 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.605306 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.149097 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcapital' | Probability: 0.092454 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġof' | Probability: 0.853825 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠFrance' | Probability: 0.284365 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.227543 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.242232 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfamous' | Probability: 0.009915 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.799097 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.072459 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠE' | Probability: 0.000333 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'iff' | Probability: 0.992043 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'el' | Probability: 0.998752 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠTower' | Probability: 0.974784 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: ',' | Probability: 0.309841 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwhich' | Probability: 0.120527 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwas' | Probability: 0.140722 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbuilt' | Probability: 0.488282 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġin' | Probability: 0.481623 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġ1889' | Probability: 0.011592 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.459811 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠThe' | Probability: 0.184742 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcity' | Probability: 0.140089 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.421538 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġknown' | Probability: 0.053417 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.633986 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.603702 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġart' | Probability: 0.006534 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġmuseums' | Probability: 0.055661 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġlike' | Probability: 0.006025 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.313182 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠLou' | Probability: 0.028593 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'vre' | Probability: 0.998887 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.308680 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.012871 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbeautiful' | Probability: 0.004029 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġarchitecture' | Probability: 0.021457 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.631402 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  p(y|x,z) = 0.000019 × 0.605306 × 0.149097 × ... × 0.004029 × 0.021457 × 0.631402 = 0.0000000000\n",
            "  Contribution to final probability: 0.05 × 0.0000000000 = 0.0000000000\n",
            "\n",
            "--- Document 4: 'Paris hosts many famous museums including the Louvre, which houses the Mona Lisa.' (p(z|x) = 0.18) ---\n",
            "\n",
            "Tokenized response (39 tokens): ['Paris', 'Ġis', 'Ġthe', 'Ġcapital', 'Ġof', 'ĠFrance', 'Ġand', 'Ġis', 'Ġfamous', 'Ġfor', 'Ġthe', 'ĠE', 'iff', 'el', 'ĠTower', ',', 'Ġwhich', 'Ġwas', 'Ġbuilt', 'Ġin', 'Ġ1889', '.', 'ĠThe', 'Ġcity', 'Ġis', 'Ġknown', 'Ġfor', 'Ġits', 'Ġart', 'Ġmuseums', 'Ġlike', 'Ġthe', 'ĠLou', 'vre', 'Ġand', 'Ġits', 'Ġbeautiful', 'Ġarchitecture', '.']\n",
            "  Token: 'Paris' | Probability: 0.000138 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.331289 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.075421 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcapital' | Probability: 0.100324 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġof' | Probability: 0.864226 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠFrance' | Probability: 0.474089 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.301374 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.177208 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfamous' | Probability: 0.027883 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.883404 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.075542 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠE' | Probability: 0.000382 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'iff' | Probability: 0.997264 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'el' | Probability: 0.999305 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠTower' | Probability: 0.985101 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: ',' | Probability: 0.365893 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwhich' | Probability: 0.195666 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwas' | Probability: 0.145634 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbuilt' | Probability: 0.505718 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġin' | Probability: 0.443236 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġ1889' | Probability: 0.008133 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.514788 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠThe' | Probability: 0.159693 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcity' | Probability: 0.078661 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.364721 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġknown' | Probability: 0.058220 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.694348 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.587251 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġart' | Probability: 0.008167 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġmuseums' | Probability: 0.074337 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġlike' | Probability: 0.029991 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.374625 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠLou' | Probability: 0.058010 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'vre' | Probability: 0.999940 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.258611 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.018497 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbeautiful' | Probability: 0.002783 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġarchitecture' | Probability: 0.022784 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.655829 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  p(y|x,z) = 0.000138 × 0.331289 × 0.075421 × ... × 0.002783 × 0.022784 × 0.655829 = 0.0000000000\n",
            "  Contribution to final probability: 0.18 × 0.0000000000 = 0.0000000000\n",
            "\n",
            "--- Document 5: 'The Seine River flows through Paris and has 37 bridges within the city limits.' (p(z|x) = 0.12) ---\n",
            "\n",
            "Tokenized response (39 tokens): ['Paris', 'Ġis', 'Ġthe', 'Ġcapital', 'Ġof', 'ĠFrance', 'Ġand', 'Ġis', 'Ġfamous', 'Ġfor', 'Ġthe', 'ĠE', 'iff', 'el', 'ĠTower', ',', 'Ġwhich', 'Ġwas', 'Ġbuilt', 'Ġin', 'Ġ1889', '.', 'ĠThe', 'Ġcity', 'Ġis', 'Ġknown', 'Ġfor', 'Ġits', 'Ġart', 'Ġmuseums', 'Ġlike', 'Ġthe', 'ĠLou', 'vre', 'Ġand', 'Ġits', 'Ġbeautiful', 'Ġarchitecture', '.']\n",
            "  Token: 'Paris' | Probability: 0.000028 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.381459 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.146898 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcapital' | Probability: 0.031459 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġof' | Probability: 0.865189 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠFrance' | Probability: 0.445792 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.280919 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.195425 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfamous' | Probability: 0.016117 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.860069 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.051989 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠE' | Probability: 0.000530 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'iff' | Probability: 0.993160 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'el' | Probability: 0.998422 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠTower' | Probability: 0.975048 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: ',' | Probability: 0.394712 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwhich' | Probability: 0.090848 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwas' | Probability: 0.141699 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbuilt' | Probability: 0.552441 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġin' | Probability: 0.479752 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġ1889' | Probability: 0.011256 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.441588 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠThe' | Probability: 0.234977 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcity' | Probability: 0.162783 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.341945 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġknown' | Probability: 0.059551 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.715305 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.598918 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġart' | Probability: 0.007653 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġmuseums' | Probability: 0.067940 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġlike' | Probability: 0.006874 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.298838 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠLou' | Probability: 0.034776 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'vre' | Probability: 0.997971 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.290305 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.011051 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbeautiful' | Probability: 0.003665 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġarchitecture' | Probability: 0.017193 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.638164 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  p(y|x,z) = 0.000028 × 0.381459 × 0.146898 × ... × 0.003665 × 0.017193 × 0.638164 = 0.0000000000\n",
            "  Contribution to final probability: 0.12 × 0.0000000000 = 0.0000000000\n",
            "\n",
            "--- Document 6: 'French cuisine is famous worldwide, with Paris having over 70 Michelin-starred restaurants.' (p(z|x) = 0.08) ---\n",
            "\n",
            "Tokenized response (39 tokens): ['Paris', 'Ġis', 'Ġthe', 'Ġcapital', 'Ġof', 'ĠFrance', 'Ġand', 'Ġis', 'Ġfamous', 'Ġfor', 'Ġthe', 'ĠE', 'iff', 'el', 'ĠTower', ',', 'Ġwhich', 'Ġwas', 'Ġbuilt', 'Ġin', 'Ġ1889', '.', 'ĠThe', 'Ġcity', 'Ġis', 'Ġknown', 'Ġfor', 'Ġits', 'Ġart', 'Ġmuseums', 'Ġlike', 'Ġthe', 'ĠLou', 'vre', 'Ġand', 'Ġits', 'Ġbeautiful', 'Ġarchitecture', '.']\n",
            "  Token: 'Paris' | Probability: 0.000053 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.387331 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.081224 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcapital' | Probability: 0.057756 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġof' | Probability: 0.848789 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠFrance' | Probability: 0.384901 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.180703 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.152354 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfamous' | Probability: 0.035526 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.816653 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.054258 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠE' | Probability: 0.000188 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'iff' | Probability: 0.987850 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'el' | Probability: 0.998724 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠTower' | Probability: 0.979241 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: ',' | Probability: 0.463053 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwhich' | Probability: 0.075035 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwas' | Probability: 0.098659 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbuilt' | Probability: 0.409425 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġin' | Probability: 0.516339 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġ1889' | Probability: 0.010773 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.421216 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠThe' | Probability: 0.155493 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcity' | Probability: 0.120671 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.385418 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġknown' | Probability: 0.077352 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.703382 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.590781 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġart' | Probability: 0.005775 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġmuseums' | Probability: 0.054095 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġlike' | Probability: 0.005969 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.324529 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠLou' | Probability: 0.036912 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'vre' | Probability: 0.999069 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.272543 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.010330 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbeautiful' | Probability: 0.004728 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġarchitecture' | Probability: 0.016235 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.626483 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  p(y|x,z) = 0.000053 × 0.387331 × 0.081224 × ... × 0.004728 × 0.016235 × 0.626483 = 0.0000000000\n",
            "  Contribution to final probability: 0.08 × 0.0000000000 = 0.0000000000\n",
            "\n",
            "--- Document 7: 'The Notre-Dame Cathedral in Paris began construction in 1163 and was damaged by fire in 2019.' (p(z|x) = 0.12) ---\n",
            "\n",
            "Tokenized response (39 tokens): ['Paris', 'Ġis', 'Ġthe', 'Ġcapital', 'Ġof', 'ĠFrance', 'Ġand', 'Ġis', 'Ġfamous', 'Ġfor', 'Ġthe', 'ĠE', 'iff', 'el', 'ĠTower', ',', 'Ġwhich', 'Ġwas', 'Ġbuilt', 'Ġin', 'Ġ1889', '.', 'ĠThe', 'Ġcity', 'Ġis', 'Ġknown', 'Ġfor', 'Ġits', 'Ġart', 'Ġmuseums', 'Ġlike', 'Ġthe', 'ĠLou', 'vre', 'Ġand', 'Ġits', 'Ġbeautiful', 'Ġarchitecture', '.']\n",
            "  Token: 'Paris' | Probability: 0.000029 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.301082 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.134900 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcapital' | Probability: 0.050464 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġof' | Probability: 0.836665 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠFrance' | Probability: 0.541970 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.289335 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.196281 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfamous' | Probability: 0.014859 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.853231 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.073638 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠE' | Probability: 0.000339 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'iff' | Probability: 0.986258 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'el' | Probability: 0.998665 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠTower' | Probability: 0.978005 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: ',' | Probability: 0.373339 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwhich' | Probability: 0.107496 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġwas' | Probability: 0.195929 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbuilt' | Probability: 0.264906 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġin' | Probability: 0.440418 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġ1889' | Probability: 0.001264 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.477258 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠThe' | Probability: 0.216818 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġcity' | Probability: 0.077030 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġis' | Probability: 0.358961 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġknown' | Probability: 0.054853 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġfor' | Probability: 0.752860 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.634048 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġart' | Probability: 0.006653 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġmuseums' | Probability: 0.045629 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġlike' | Probability: 0.008220 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġthe' | Probability: 0.309934 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'ĠLou' | Probability: 0.054335 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'vre' | Probability: 0.998475 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġand' | Probability: 0.299106 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġits' | Probability: 0.010149 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġbeautiful' | Probability: 0.004513 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: 'Ġarchitecture' | Probability: 0.018006 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  Token: '.' | Probability: 0.629174 | Given context: 'What are some interesting facts about Paris, Franc......'\n",
            "  p(y|x,z) = 0.000029 × 0.301082 × 0.134900 × ... × 0.004513 × 0.018006 × 0.629174 = 0.0000000000\n",
            "  Contribution to final probability: 0.12 × 0.0000000000 = 0.0000000000\n",
            "\n",
            "--- Final RAG-Sequence Probability ---\n",
            "p_RAG-Sequence(y|x) = 1.4948820803e-38 + 1.3869488878e-39 + 1.2235430535e-40 + 7.9667589768e-38 + 4.9928639832e-40 + 4.6092518023e-41 + 3.1861323183e-41 = 9.6702954004e-38\n",
            "\n",
            "--- Document Contribution Analysis ---\n",
            "Document 4: 82.38% of final probability\n",
            "  - Content: 'Paris hosts many famous museums including the Louvre, which houses the Mona Lisa.'\n",
            "  - p(z|x): 0.18\n",
            "  - Contribution: 7.9667589768e-38\n",
            "\n",
            "Document 1: 15.46% of final probability\n",
            "  - Content: 'Paris is the capital of France and is known as the City of Light.'\n",
            "  - p(z|x): 0.25\n",
            "  - Contribution: 1.4948820803e-38\n",
            "\n",
            "Document 2: 1.43% of final probability\n",
            "  - Content: 'The Eiffel Tower in Paris was built for the 1889 World's Fair and stands 324 meters tall.'\n",
            "  - p(z|x): 0.2\n",
            "  - Contribution: 1.3869488878e-39\n",
            "\n",
            "Document 5: 0.52% of final probability\n",
            "  - Content: 'The Seine River flows through Paris and has 37 bridges within the city limits.'\n",
            "  - p(z|x): 0.12\n",
            "  - Contribution: 4.9928639832e-40\n",
            "\n",
            "Document 3: 0.13% of final probability\n",
            "  - Content: 'France is a country in Western Europe with a population of about 67 million people.'\n",
            "  - p(z|x): 0.05\n",
            "  - Contribution: 1.2235430535e-40\n",
            "\n",
            "Document 6: 0.05% of final probability\n",
            "  - Content: 'French cuisine is famous worldwide, with Paris having over 70 Michelin-starred restaurants.'\n",
            "  - p(z|x): 0.08\n",
            "  - Contribution: 4.6092518023e-41\n",
            "\n",
            "Document 7: 0.03% of final probability\n",
            "  - Content: 'The Notre-Dame Cathedral in Paris began construction in 1163 and was damaged by fire in 2019.'\n",
            "  - p(z|x): 0.12\n",
            "  - Contribution: 3.1861323183e-41\n",
            "\n",
            "--- Token Probability Analysis ---\n",
            "\n",
            "Analyzing token: 'Paris'\n",
            "  Position 0 ('Paris')\n",
            "    Doc 1: 0.000183 - 'Paris is the capital of France and is known as the...'\n",
            "    Doc 4: 0.000138 - 'Paris hosts many famous museums including the Louv...'\n",
            "    Doc 6: 0.000053 - 'French cuisine is famous worldwide, with Paris hav...'\n",
            "\n",
            "Analyzing token: 'Eiffel'\n",
            "  Token not found directly in response\n",
            "\n",
            "Analyzing token: 'Tower'\n",
            "  Position 14 ('ĠTower')\n",
            "    Doc 4: 0.985101 - 'Paris hosts many famous museums including the Louv...'\n",
            "    Doc 6: 0.979241 - 'French cuisine is famous worldwide, with Paris hav...'\n",
            "    Doc 7: 0.978005 - 'The Notre-Dame Cathedral in Paris began constructi...'\n",
            "\n",
            "Analyzing token: 'Louvre'\n",
            "  Token not found directly in response\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "37W8osWV-xCy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}