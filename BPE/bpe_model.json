{
  "vocab_size": 500,
  "vocab": {
    "<PAD>": 0,
    "<UNK>": 1,
    "<BOS>": 2,
    "<EOS>": 3,
    " ": 4,
    "-": 5,
    ".": 6,
    "A": 7,
    "B": 8,
    "C": 9,
    "D": 10,
    "E": 11,
    "F": 12,
    "G": 13,
    "L": 14,
    "M": 15,
    "N": 16,
    "O": 17,
    "P": 18,
    "R": 19,
    "S": 20,
    "T": 21,
    "V": 22,
    "W": 23,
    "a": 24,
    "b": 25,
    "c": 26,
    "d": 27,
    "e": 28,
    "f": 29,
    "g": 30,
    "h": 31,
    "i": 32,
    "j": 33,
    "k": 34,
    "l": 35,
    "m": 36,
    "n": 37,
    "o": 38,
    "p": 39,
    "q": 40,
    "r": 41,
    "s": 42,
    "t": 43,
    "u": 44,
    "v": 45,
    "w": 46,
    "x": 47,
    "y": 48,
    "z": 49,
    "s ": 50,
    "e ": 51,
    "in": 52,
    "en": 53,
    "an": 54,
    "ar": 55,
    "on": 56,
    "or": 57,
    "er": 58,
    "re": 59,
    "at": 60,
    " t": 61,
    "ing": 62,
    "ion": 63,
    "od": 64,
    "el": 65,
    "t ": 66,
    "ro": 67,
    "ing ": 68,
    "ec": 69,
    "ra": 70,
    "s.": 71,
    "ag": 72,
    "d ": 73,
    "he ": 74,
    "for": 75,
    "wor": 76,
    "y ": 77,
    "pre": 78,
    "ch": 79,
    "mod": 80,
    "model": 81,
    "iz": 82,
    "ation": 83,
    "l ": 84,
    "ne": 85,
    "qu": 86,
    "le": 87,
    "ce": 88,
    "se": 89,
    "om": 90,
    "ok": 91,
    "oken": 92,
    "ation ": 93,
    "pro": 94,
    "gu": 95,
    "it": 96,
    "ent": 97,
    "ic": 98,
    "s o": 99,
    "enc": 100,
    "e t": 101,
    "lan": 102,
    "guag": 103,
    "ut": 104,
    "ran": 105,
    "rain": 106,
    "er ": 107,
    "a ": 108,
    "pres": 109,
    "lear": 110,
    "learn": 111,
    "okeniz": 112,
    "okenization ": 113,
    "ex": 114,
    "proce": 115,
    "proces": 116,
    "ura": 117,
    "ural ": 118,
    "languag": 119,
    "un": 120,
    "rans": 121,
    "form": 122,
    "ect": 123,
    "ur": 124,
    "s t": 125,
    "ver": 126,
    "pa": 127,
    "dat": 128,
    "com": 129,
    "ech": 130,
    "learning ": 131,
    "ext ": 132,
    "language ": 133,
    "vo": 134,
    "ed ": 135,
    "al ": 136,
    "arch": 137,
    "ransform": 138,
    "for ": 139,
    "iv": 140,
    "-t": 141,
    "ct": 142,
    "repres": 143,
    "s of": 144,
    "as": 145,
    "ent ": 146,
    "word": 147,
    "in ": 148,
    "ural ne": 149,
    "ural net": 150,
    "ural networ": 151,
    "ural network": 152,
    "ural networks ": 153,
    "es ": 154,
    "lar": 155,
    "The ": 156,
    " b": 157,
    "wn": 158,
    "fo": 159,
    "um": 160,
    " the ": 161,
    "y d": 162,
    "pai": 163,
    "pair": 164,
    "encod": 165,
    "is ": 166,
    "ach": 167,
    "models ": 168,
    " text ": 169,
    "process": 170,
    "ing.": 171,
    "put": 172,
    "st": 173,
    "and ": 174,
    "as ": 175,
    "fic": 176,
    "ransformer": 177,
    "archit": 178,
    "architect": 179,
    "models.": 180,
    "and": 181,
    "rained ": 182,
    "represent": 183,
    "fro": 184,
    "from": 185,
    "s the ": 186,
    "o ": 187,
    "sm": 188,
    "on ": 189,
    "data": 190,
    "data.": 191,
    "use": 192,
    "ou": 193,
    "neural networks ": 194,
    "sequ": 195,
    "are ": 196,
    "im": 197,
    "ask": 198,
    " train": 199,
    " tokenization ": 200,
    "ca": 201,
    "cab": 202,
    "cabu": 203,
    "cabular": 204,
    "cabulary ": 205,
    "act": 206,
    "The qu": 207,
    "The quic": 208,
    "The quick": 209,
    "The quick b": 210,
    "The quick bro": 211,
    "The quick brown": 212,
    "The quick brown ": 213,
    "The quick brown fo": 214,
    "The quick brown fox": 215,
    "The quick brown fox ": 216,
    "The quick brown fox j": 217,
    "The quick brown fox jum": 218,
    "The quick brown fox jump": 219,
    "The quick brown fox jumps o": 220,
    "The quick brown fox jumps over": 221,
    "The quick brown fox jumps over the ": 222,
    "The quick brown fox jumps over the l": 223,
    "The quick brown fox jumps over the la": 224,
    "The quick brown fox jumps over the laz": 225,
    "The quick brown fox jumps over the lazy d": 226,
    "The quick brown fox jumps over the lazy do": 227,
    "The quick brown fox jumps over the lazy dog": 228,
    "By": 229,
    "Byt": 230,
    "Byte ": 231,
    "Byte pair": 232,
    "Byte pair ": 233,
    "Byte pair encod": 234,
    "Byte pair encoding ": 235,
    "is a ": 236,
    " tech": 237,
    " techn": 238,
    " techni": 239,
    " techniqu": 240,
    "e.": 241,
    "achin": 242,
    "achine ": 243,
    "achine learning ": 244,
    "processing.": 245,
    "hel": 246,
    "help": 247,
    "comput": 248,
    "und": 249,
    "and h": 250,
    "vol": 251,
    "volut": 252,
    "volution": 253,
    "art": 254,
    "ific": 255,
    "ial ": 256,
    "int": 257,
    "Transformer": 258,
    "ve ": 259,
    "dom": 260,
    "ant ": 261,
    "architectur": 262,
    "architecture ": 263,
    "for language ": 264,
    "for language models.": 265,
    "T ": 266,
    "erat": 267,
    "erativ": 268,
    "-trained ": 269,
    "di": 270,
    "rea": 271,
    "al": 272,
    "all": 273,
    "ge ": 274,
    "mo": 275,
    "s s": 276,
    "f-": 277,
    "tent": 278,
    "tention": 279,
    "tention ": 280,
    "tention m": 281,
    "tention mech": 282,
    "tention mechan": 283,
    "tention mechani": 284,
    "tention mechanism": 285,
    "Wor": 286,
    "words ": 287,
    "se ": 288,
    "con": 289,
    "cont": 290,
    "from ": 291,
    "ari": 292,
    "e task": 293,
    "sp": 294,
    "aga": 295,
    "word ": 296,
    "prev": 297,
    "vocabulary ": 298,
    "siz": 299,
    "size ": 300,
    "aract": 301
  },
  "merges": {
    "s  ": "s ",
    "e  ": "e ",
    "i n": "in",
    "e n": "en",
    "a n": "an",
    "a r": "ar",
    "o n": "on",
    "o r": "or",
    "e r": "er",
    "r e": "re",
    "a t": "at",
    "  t": " t",
    "in g": "ing",
    "i on": "ion",
    "o d": "od",
    "e l": "el",
    "t  ": "t ",
    "r o": "ro",
    "ing  ": "ing ",
    "e c": "ec",
    "r a": "ra",
    "s .": "s.",
    "a g": "ag",
    "d  ": "d ",
    "h e ": "he ",
    "f or": "for",
    "w or": "wor",
    "y  ": "y ",
    "p re": "pre",
    "c h": "ch",
    "m od": "mod",
    "mod el": "model",
    "i z": "iz",
    "at ion": "ation",
    "l  ": "l ",
    "n e": "ne",
    "q u": "qu",
    "l e": "le",
    "c e": "ce",
    "s e": "se",
    "o m": "om",
    "o k": "ok",
    "ok en": "oken",
    "ation  ": "ation ",
    "p ro": "pro",
    "g u": "gu",
    "i t": "it",
    "en t": "ent",
    "i c": "ic",
    "s  o": "s o",
    "en c": "enc",
    "e  t": "e t",
    "l an": "lan",
    "gu ag": "guag",
    "u t": "ut",
    "r an": "ran",
    "ra in": "rain",
    "er  ": "er ",
    "a  ": "a ",
    "pre s": "pres",
    "le ar": "lear",
    "lear n": "learn",
    "oken iz": "okeniz",
    "okeniz ation ": "okenization ",
    "e x": "ex",
    "pro ce": "proce",
    "proce s": "proces",
    "u ra": "ura",
    "ura l ": "ural ",
    "lan guag": "languag",
    "u n": "un",
    "ran s": "rans",
    "for m": "form",
    "ec t": "ect",
    "u r": "ur",
    "s  t": "s t",
    "v er": "ver",
    "p a": "pa",
    "d at": "dat",
    "c om": "com",
    "ec h": "ech",
    "learn ing ": "learning ",
    "ex t ": "ext ",
    "languag e ": "language ",
    "v o": "vo",
    "e d ": "ed ",
    "a l ": "al ",
    "ar ch": "arch",
    "rans form": "ransform",
    "for  ": "for ",
    "i v": "iv",
    "- t": "-t",
    "c t": "ct",
    "re pres": "repres",
    "s o f": "s of",
    "a s": "as",
    "en t ": "ent ",
    "wor d": "word",
    "in  ": "in ",
    "ural  ne": "ural ne",
    "ural ne t": "ural net",
    "ural net wor": "ural networ",
    "ural networ k": "ural network",
    "ural network s ": "ural networks ",
    "e s ": "es ",
    "l ar": "lar",
    "T he ": "The ",
    "  b": " b",
    "w n": "wn",
    "f o": "fo",
    "u m": "um",
    " t he ": " the ",
    "y  d": "y d",
    "pa i": "pai",
    "pai r": "pair",
    "enc od": "encod",
    "i s ": "is ",
    "a ch": "ach",
    "model s ": "models ",
    " t ext ": " text ",
    "proces s": "process",
    "ing .": "ing.",
    "p ut": "put",
    "s t": "st",
    "an d ": "and ",
    "a s ": "as ",
    "f ic": "fic",
    "ransform er": "ransformer",
    "arch it": "archit",
    "archit ect": "architect",
    "model s.": "models.",
    "an d": "and",
    "rain ed ": "rained ",
    "repres ent": "represent",
    "f ro": "fro",
    "fro m": "from",
    "s t he ": "s the ",
    "o  ": "o ",
    "s m": "sm",
    "on  ": "on ",
    "dat a": "data",
    "data .": "data.",
    "u se": "use",
    "o u": "ou",
    "ne ural networks ": "neural networks ",
    "se qu": "sequ",
    "ar e ": "are ",
    "i m": "im",
    "as k": "ask",
    " t rain": " train",
    " t okenization ": " tokenization ",
    "c a": "ca",
    "ca b": "cab",
    "cab u": "cabu",
    "cabu lar": "cabular",
    "cabular y ": "cabulary ",
    "a ct": "act",
    "The  qu": "The qu",
    "The qu ic": "The quic",
    "The quic k": "The quick",
    "The quick  b": "The quick b",
    "The quick b ro": "The quick bro",
    "The quick bro wn": "The quick brown",
    "The quick brown  ": "The quick brown ",
    "The quick brown  fo": "The quick brown fo",
    "The quick brown fo x": "The quick brown fox",
    "The quick brown fox  ": "The quick brown fox ",
    "The quick brown fox  j": "The quick brown fox j",
    "The quick brown fox j um": "The quick brown fox jum",
    "The quick brown fox jum p": "The quick brown fox jump",
    "The quick brown fox jump s o": "The quick brown fox jumps o",
    "The quick brown fox jumps o ver": "The quick brown fox jumps over",
    "The quick brown fox jumps over  the ": "The quick brown fox jumps over the ",
    "The quick brown fox jumps over the  l": "The quick brown fox jumps over the l",
    "The quick brown fox jumps over the l a": "The quick brown fox jumps over the la",
    "The quick brown fox jumps over the la z": "The quick brown fox jumps over the laz",
    "The quick brown fox jumps over the laz y d": "The quick brown fox jumps over the lazy d",
    "The quick brown fox jumps over the lazy d o": "The quick brown fox jumps over the lazy do",
    "The quick brown fox jumps over the lazy do g": "The quick brown fox jumps over the lazy dog",
    "B y": "By",
    "By t": "Byt",
    "Byt e ": "Byte ",
    "Byte  pair": "Byte pair",
    "Byte pair  ": "Byte pair ",
    "Byte pair  encod": "Byte pair encod",
    "Byte pair encod ing ": "Byte pair encoding ",
    "is  a ": "is a ",
    " t ech": " tech",
    " tech n": " techn",
    " techn i": " techni",
    " techni qu": " techniqu",
    "e .": "e.",
    "ach in": "achin",
    "achin e ": "achine ",
    "achine  learning ": "achine learning ",
    "process ing.": "processing.",
    "h el": "hel",
    "hel p": "help",
    "com put": "comput",
    "un d": "und",
    "and  h": "and h",
    "vo l": "vol",
    "vol ut": "volut",
    "volut ion": "volution",
    "ar t": "art",
    "i fic": "ific",
    "i al ": "ial ",
    "in t": "int",
    "T ransformer": "Transformer",
    "v e ": "ve ",
    "d om": "dom",
    "an t ": "ant ",
    "architect ur": "architectur",
    "architectur e ": "architecture ",
    "for  language ": "for language ",
    "for language  models.": "for language models.",
    "T  ": "T ",
    "er at": "erat",
    "erat iv": "erativ",
    "-t rained ": "-trained ",
    "d i": "di",
    "re a": "rea",
    "a l": "al",
    "al l": "all",
    "g e ": "ge ",
    "m o": "mo",
    "s  s": "s s",
    "f -": "f-",
    "t ent": "tent",
    "tent ion": "tention",
    "tention  ": "tention ",
    "tention  m": "tention m",
    "tention m ech": "tention mech",
    "tention mech an": "tention mechan",
    "tention mechan i": "tention mechani",
    "tention mechani sm": "tention mechanism",
    "W or": "Wor",
    "word s ": "words ",
    "s e ": "se ",
    "c on": "con",
    "con t": "cont",
    "from  ": "from ",
    "ar i": "ari",
    "e t ask": "e task",
    "s p": "sp",
    "ag a": "aga",
    "wor d ": "word ",
    "pre v": "prev",
    "vo cabulary ": "vocabulary ",
    "s iz": "siz",
    "siz e ": "size ",
    "ar act": "aract"
  },
  "special_tokens": {
    "<PAD>": 0,
    "<UNK>": 1,
    "<BOS>": 2,
    "<EOS>": 3
  }
}